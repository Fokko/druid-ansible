druid.host={{ ansible_fqdn }}:{{ port }}
druid.port={{ port }}
druid.service=historical

#druid.extensions.coordinates=["io.druid.extensions:druid-s3-extensions:0.6.160"]

druid.zk.service.host={{ zookeeper }}
druid.zk.paths.base=/druid/prod

druid.server.maxSize=100000000000
druid.server.http.numThreads=50

druid.processing.numThreads=3
druid.processing.buffer.sizeBytes=1073741824
druid.query.groupBy.maxResults=1000000

druid.segmentCache.locations=[{"path": "{{ segment_cache_location }}", "maxSize": 300000000000}]

druid.request.logging.type=file
druid.request.logging.dir=request_logs/

druid.storage.type={{ deep_storage_type }}
druid.storage.storageDirectory={{ deep_storage_location }}
druid.extensions.coordinates=["io.druid.extensions:druid-hdfs-storage:{{ druid_version }}"]
druid.extensions.searchCurrentClassloader=true
druid.extensions.remoteRepositories=[{{ remote_repositories }}]
#druid.monitoring.monitors=["io.druid.server.metrics.ServerMonitor", "com.metamx.metrics.SysMonitor","com.metamx.metrics.JvmMonitor"]

# Emit metrics over http
#druid.emitter=http
#druid.emitter.http.recipientBaseUrl=#{EMITTER_URL}

# If you choose to compress ZK announcements, you must do so for every node type
druid.announcer.type=batch
druid.curator.compress=true

